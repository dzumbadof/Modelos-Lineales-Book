# Bitácora 4

## Segundo intento de inferencia

### ARIMA

```{r, R.options, echo=F, include=F, warning=F, message=F}
options(knitr.kable.NA = '-', echo = F)
library(readxl)
library(kableExtra)
library(dplyr)
library(janitor)
library(ggplot2)
library(wesanderson)
library(cowplot)
library(viridis)
library(GGally)
library(scales)
library(ggplot2)
library(ggpubr) # qqplots en ggplot2
#Paquetes para series de tiempo
library(astsa)
library(tseries)
library(forecast)


#Paquetes para DLM:

library(devtools)

devtools::install_github("https://github.com/cran/dlm")

install.packages("dlm", repos = "https://cran.rstudio.com/", 
    dependencies = TRUE)

library(dlm)
library(ggmcmc) #Para ACF Y PACF DLM .
```

```{r, echo=F, include=F}
base <- data.frame(read_excel("sepoblacev1950-2020_0.xls", 
    range = "B9:S80", col_types = "numeric"))

colnames(base) <- c("Año",
                    "Población total",
                    "Población de hombres",
                    "Población de mujeres",
                    "Nacimientos",
                    "Defunciones",
                    "Defunciones infantiles",
                    "Defunciones neonatales",
                    "Defunciones fetales",
                    "Tasa de crecimiento",
                    "Tasa de natalidad",
                    "Tasa de mortalidad",
                    "Tasa de mortalidad infantil",
                    "Tasa de mortalidad neonatal",
                    "Tasa de mortalidad fetal",
                    "Tasa global de fecundidad",
                    "Tasa bruta de reproducción",
                    "Tasa neta de reproducción"				
)

base <- base %>% clean_names()

 
```

```{r}
#| echo: false
entrenamiento <- base$defunciones[1:69]
serie <- ts( entrenamiento, start=c(1950,1), frequency=1)
```

En la bitácora anterior se hizo un ajuste de un modelo ARIMA a la serie de defunciones totales. En esta bitácora nuevamente se hará un ajuste similar, y a pesar de que el modelo escogido es el mismo, se hará un análisis más certero sobre los grados implicados por los gráficos de ACF y PACF empíricos, los diagnósticos de los modelos y se hará una comparación entre tres propuestas. Este último elemento fue particularmente faltante en la última bitácora.


```{r}
#| fig-cap: "Serie de tiempo de defunciones totales"
#| label: fig-serieDefunciones
#| fig-cap-location: top
#| echo: false
plot(serie, main="", xlab="Tiempo", ylab='Defunciones totales')
```

```{r}
#| fig-cap: "ACF y PACF de la serie de defunciones totales con una diferencia"
#| label: fig-ACFDefunciones
#| fig-cap-location: top
#| echo: false
t<-acf2(serie, main="")
```

En la @fig-serieDefunciones se observa que la serie de defunciones totales no es estacionaria. Esto se confirma con el gráfico en la @fig-ACFDefunciones confirma que la decadencia de las correlaciones no es suficientemente rápida. Se lleva a cabo un diferencia para tratar de eliminar la tendencia.

```{r}
#| echo: false
seriedif <- diff(serie)
seriedif2 <- diff(serie, differences = 2)
```

```{r}
#| echo: false
#| layout-ncol: 2
#| fig-cap: "Gráficos para la serie de defunciones totales con una y dos diferencias"
#| fig-subcap:
#|    - "Serie con una diferencia"
#|    - "ACF y PACF de serie con una diferencia"
#|    - "Serie con dos diferencias"
#|    - "ACF y PACF de serie con dos diferencias"
#| label: fig-graficosDiferencias


plot(seriedif, xlab='Tiempo', ylab="")
t<-acf2(seriedif, main="")
plot(seriedif2, xlab='Tiempo', ylab='')
t<-acf2(seriedif2, main="")
```

En la @fig-graficosDiferencias se observa que aún con una diferencias es discernible una tendencia, particularmente luego de 1970 donde es creciente. Al aplicarle una segunda diferencia se obtiene una serie que parece ser estacionaria. Observando el ACF empírico se nota que la decadencia de las correlaciones es suficientemente rápida. Se procede a hacer el ajuste del modelo para la serie con dos diferencias. En la @fig-graficosDiferencias se ve en los gráficos de ACF y PACF para la serie con dos diferencias que el ACF se corta luego del primer rezago, mientras que el PACF tiene una decadencia gradual. Esto implica un modelo MA(1). También es posible que haya una decadencia gradual del ACF y PACF, lo que implicaría un modelo ARMA(1,1) o ARMA(2,2). Por lo tanto los modelos propuestos son  MA(1) o equivalentemente ARMA(0,1), ARMA(1,1), ARMA(2,1), ARMA(2,2).  

```{r}
#| echo: false
#| fig-cap: 'Diagnósticos del modelo ARIMA(0,2,1)'
#| label: fig-diagMa1
modelo1 <- sarima(seriedif2, 0,2,1)
```

```{r}
#| echo: false
#| fig-cap: 'Diagnósticos del modelo ARIMA(1,2,1)'
#| label: fig-diagARIMA121
modelo2 <- sarima(serie, 1,2,1)
```
```{r}
#| echo: false
#| fig-cap: 'Diagnósticos del modelo ARIMA(2,2,1)'
#| label: fig-diagARIMA221
modelo3 <- sarima(serie, 2,2,1)
```

```{r}
#| echo: false
#| fig-cap: 'Diagnósticos del modelo ARIMA(2,2,2)'
#| label: fig-diagARIMA222
modelo4 <- sarima(serie, 2,2,2)
```

En la @fig-diagMa1 se observa que se obtienen residuos que aparentan no tener varianza constante, específicamente se observa que las innovaciones estandarizadas tienen menor varianza entre 1975 y el 2000. Además, a pesar de ajustarse bien a una normal, se observa en el ACF que conservan un alto grado de dependencia, lo cual también se confirma con el estadístico Q de Box-Pierce-Ljung, en el cual se obtiene un valor-p consistentemente en la zona de rechazo. Se concluye que el modelo MA(1) no es un buen ajuste. Observando los diagnósticos de los otros modelos se obtienen residuos que parecen ser ruido blanco. Se observa que en el caso del modelo ARIMA(1,2,1) se da un no rechazo de la independencia según la pruba de Ljung-Box. Se consideran los modelos ARIMA(1,2,1) ARIMA(2,2,1) Y ARIMA(2,2,2) como candidatos no rechazados. 

```{r}
#| echo: false
modelo <- c('ARIMA(1,2,1)', 'ARIMA(2,2,1)' , 'ARIMA(2,2,2)') 
W <- rep(NA, 3) #estadistico de Shapiro-Wilks
SWp <- rep(NA,3) #Valor p de prueba Shapiro-Wilks

Q <- rep(NA,3) #estadistico de Ljung-Box
LBp <- rep(NA,3) #valor p de prueba de Ljung-Box
```

```{r}
#| echo: false  
# Pruebas Shapiro-Wilks de normalidad y Ljung-Box de independencia

#Modelo ARIMA(1,2,1)
std.innov <- modelo2$fit$residuals/sqrt(modelo2$fit$sigma2)
W[1] <- shapiro.test(std.innov)$statistic
SWp[1] <- shapiro.test(std.innov)$p.value
Q[1] <- Box.test(std.innov, type='Ljung')$statistic
LBp[1] <- Box.test(std.innov, type='Ljung')$p.value

#Modelo ARIMA(2,2,1)
std.innov <- modelo3$fit$residuals/sqrt(modelo3$fit$sigma2)
W[2] <- shapiro.test(std.innov)$statistic
SWp[2] <- shapiro.test(std.innov)$p.value
Q[2] <- Box.test(std.innov, type='Ljung')$statistic
LBp[2] <- Box.test(std.innov, type='Ljung')$p.value

#Modelo ARIMA(2,2,2)
std.innov <- modelo4$fit$residuals/sqrt(modelo4$fit$sigma2)
W[3] <- shapiro.test(std.innov)$statistic
SWp[3] <- shapiro.test(std.innov)$p.value
Q[3] <- Box.test(std.innov, type='Ljung')$statistic
LBp[3] <- Box.test(std.innov, type='Ljung')$p.value
```

```{r}
#| echo: false
# AIC Y BIC de los modelos

AIC <- c(modelo2$AIC, modelo3$AIC, modelo4$AIC)
BIC <- c(modelo2$BIC, modelo3$BIC, modelo4$BIC)
AICc <- c(modelo2$AICc, modelo3$AICc, modelo4$AICc)
```


```{r}
#| tbl-cap: "Resumen de diagnósticos de los modelos propuestos"
#| label: tbl-diagARIMA
#| tbl-pos: 'h'
#| echo: false
data.frame(modelo, W, SWp, Q, LBp, AIC, BIC, AICc) %>%
  kbl(
    digits = 2,
    col.names = c(
      'Modelo',
      'Estadístico W',
      "Valor p Shapiro-Wilks",
      "Estadístico Q",
      "Valor p Ljung-Box",
      "AIC",
      "BIC",
      "AICc"
    )
  ) %>%
  kable_styling(latex_options = c("striped"))  %>%
  kable_styling(full_width = F) %>% kable_classic_2() %>% row_spec(0, bold =
                                                                     TRUE)
```

La @tbl-diagARIMA resume las pruebas Shapiro-Wilks de normalidad y Ljung-Box de independencia de los residuos estandarizados. Se da un no rechazo de las hipótesis nulas en los tres modelos, lo que confirma que los tres pueden ser viables. Al examinar el se observa que el modelo ARIMA(1,2,1) Obtuvo el menor valor en el BIC y en el AICc. Para el AIC, el modelo ARIMA(2,2,2) obtuvo el menor valor, sin embargo el modelo más simple también resultó extremadamente cercano. Por el principio de parsimonía y por el posible impacto que tenga el sobreajuste sobre el pronóstico se decide escoger el modelo ARIMA(1,2,1). Se procede a hacer el pronóstico. 

```{r}
#| echo: false
def.for <- sarima.for(serie, n.ahead = 2, 1,2,1)
```
```{r}
#| echo: false
# Intervalos de confianza
U95 <- def.for$pred + def.for$se*qnorm(1-0.95/2)
L95 <- def.for$pred - def.for$se*qnorm(1-0.95/2)

U80 <- def.for$pred + def.for$se*qnorm(1-0.8/2)
L80 <- def.for$pred - def.for$se*qnorm(1-0.8/2)


for.int <- data.frame(c(2019, 2020), def.for$pred, L80, U80, L95, U95)
```

```{r}
#| tbl-cap: "Intervalos de confianza del modelo ARIMA(1,2,1)"
#| label: tbl-forARIMA
#| tbl-pos: 'h'
#| echo: false
for.int %>% kbl(
  digits = 0,
  col.names = c('Año', 'pred', 'Lower80', 'Upper80', 'Lower95', 'Upper95')
) %>%
  kable_styling(latex_options = c("striped"))  %>%
  kable_styling(full_width = F) %>% kable_classic_2() %>% row_spec(0, bold =
                                                                     TRUE)
```

La @tbl-forARIMA muestra el valor pronosticado para las defunciones totales en los años 2019 y 2020 y los intervalos de confianza al 80% y 95%. Al comparar con los valores reales de 24292 para el 2019 y 26209 para el 2020

```{r}
#| echo: false
abs( as.numeric(def.for$pred) - base$defunciones[70:71])
```


### DLM polinomial de orden 1

Este modelo está descrito por el par de ecuaciones:
\[
\begin{aligned}
Y_t &=\mu_t+v_t, & v_t \sim \mathcal{N}(0, V) \\
\mu_t &=\mu_{t-1}+w_t, & w_t \sim \mathcal{N}(0, W)
\end{aligned}
\]

donde $(Y_{t})$ es, para efectos del presente análisis, el proceso del total de defunciones anuales de Costa Rica. Para utilizar un DLM polinomial de orden 1, se empieza por estimar los parámetros $V$ y $W$ correspondientes a la varianza de el ruido blanco gaussiano aditivo en las ecuaciones observada y del sistema, respectivamente. Esto se lleva a cabo por máxima verosimilitud, y se obtiene $\hat{V}=0.37$ y $\hat{W}=304117$. Nótese la gran diferencia en escala entre ambas varianzas. En @petrisDLM se advierte que este modelo en particular es muy sensible respecto al valor de la razón $\frac{W}{V}$, llamada *radio señal-ruido*. Cabe mencionar también que este proceso se comporta asintóticamente como un ARIMA(0,1,1) [@petrisDLM].


```{r Estimación DLM orden 1, echo=FALSE}
#| echo: false

serie1980 <- window(serie, start=1980)

# serie_insumo <- window( serie, end = 1979)
# m0_prueba = mean(serie_insumo)
# C0_prueba = var(serie_insumo)

# Se crea la estructura del modelo DLM orden 1:

DLMOrden1 <- function(parm) {
      dlmModPoly(order = 1, dV = exp(parm[1]), dW = exp(parm[2]))
}

# Se procede hacer ajuste de parametros vía maxima verosimilitud:

ajusteDlmOrden1 <- dlmMLE(serie1980, rep(0, 2), build = DLMOrden1, hessian = TRUE)


# Se crea el modelo con los parametros obtenidos vía maxima verosimilitud:

modeloDlmOrden1 <- DLMOrden1(ajusteDlmOrden1$par)

round(modeloDlmOrden1$V, 2)
round(modeloDlmOrden1$W, 2)
```


Una vez obtenidos estos parámetros, se procede a aplicar el filtro de Kalman y con este se realiza el pronóstico de la cantidad total de defunciones para 2019 y 2020, donde se encuentra un inconveniente: para ambos años, el pronóstico es de 23786 defunciones. Más aún, esta cantidad es justamente el total de defunciones en  2018. Sin duda esto representa una gran desventaja de este modelo pues claramente no resulta útil en términos de predicción, incluso teniendo en cuenta que solo es prudente tener pronósitcos de corto plazo. Este  puede ser explicada por el gran desbalance que existe entre las varianzas de los ruidos de cada ecuación del modelo, lo que se traduce en un radio señal-ruido muy alto.

En efecto, en conformidad con @petrisDLM el filtro de Kalman para este simple modelo puede ser expresado de la siguiente manera:
\[
\begin{aligned}
y_{1: t-1} & \sim \mathcal{N}\left(m_{t-1}, R_t=C_{t-1}+W\right) \\
Y_t \mid y_{1: t-1} & \sim \mathcal{N}\left(f_t=m_{t-1}, Q_t=R_t+V\right) \\
\mu_t \mid y_{1: t} & \sim \mathcal{N}\left(m_t=m_{t-1}+K_t e_t, C_t=K_t V\right)
\end{aligned}
\]

donde la notación $y_{1: s}$ hace referencia a las observaciones $y_{1}, y_{2}, \dots, y_{s}$, $e_{t}=Y_{t}-f_{t}$ y

\[
K_{t}=\frac{R_{t}}{Q_{t}}=\frac{C_{t-1}+W}{C_{t-1}+W+V}=1-\frac{1}{\frac{C_{t-1}}{V}+\frac{W}{V}+1}.
\]
De la última ecuación se tiene que para valores altos de $\frac{W}{V}$, $K_{t}$ es cercano a 1. De las mismas ecuaciones que concede el filtro de Kalman se extrae la recursión
\[
m_{t}=K_{t}y_{t}+(1-K_{t})\,m_{t-1},
\]
de forma que $K_{t}$ funciona como un peso, y si $\frac{W}{V}$ es grande, entonces $m_{t}$ es "similar" a $y_{t}$ y, por lo tanto, el pronóstico a un paso se parece mucho a la última observación. En un caso extremo en que $V=0$, entonces $m_{t}=y_{t}$, es decir, el pronóstico a un paso es exactamente la observación más reciente. Es precisamente este fenómeno el que podría estar desembocando en el poco provecho del modelo en términos de sus pronósticos. 

```{r, echo=FALSE}

#| echo: false 

DLMOrden1 <- function(parm) {
      dlmModPoly(order = 1, 
                 dV = exp(parm[1]), 
                 dW = exp(parm[2]))
}
# Ajuste máxima verosimilitud
ajusteDlmOrden1 <- dlmMLE(serie1980, rep(0, 2), build = DLMOrden1, hessian = TRUE)
# Se aplica el filtro de Kalman:
filtroDLM1 <-  dlmFilter(serie1980, mod = modeloDlmOrden1)
# Se realiza el pronóstico
forecastDLM1 <-  dlmForecast(mod = filtroDLM1, nAhead = 2)
forecastDLM1$f
```

```{r Pronóstico DLM orden 1}
#| echo: false 

# Se aplica el filtro de Kalman:

filtroDLM1 <-  dlmFilter(serie1980, mod = modeloDlmOrden1)

# Procedemos a hacer forecast, en este caso se hace se hace forecating 2 pasos adelante.

forecastDLM1 <-  dlmForecast(mod = filtroDLM1, nAhead = 2)

forecastDLM1


```

En cuanto a los diagnósticos del modelo, en la @fig-diagDLM1 se observa del gráfico de residuos que hay algunos de estos muy cercanos a 2 en valor absoluto, aunque en general no se aprecia con claridad un valor extremo. Por su parte, en el ACF, la proporción de excepciones a la regla empírica es adecuada, siendo una proporción menor al 5% del total de rezagos usados (20), de modo que estos parecen no estar correlacionados. Con la prueba de Ljung-Box en la @fig-pvaluesLjBDLM1 se ve aún más sustentado que los residuos no estén correlacionados. Sin embargo, hay graves problemas con el supuesto de normalidad. En primera instancia, del histograma presente en la @fig-diagDLM1, el ajuste normal parece no ser bueno. Esto se constata con el gráfico cuantil-cuantil en la @fig-diagqqplotDLM1, donde se nota un muy mal ajuste en ambas colas. A pesar de que con pruebas como la de Shapiro-Wilk no se rechazaría la hipótesis de normalidad con niveles de significancia usuales del 1% y 5%, teniéndose un valor p de cerca del 8%, del gráfico cuantil-cuantil ya discutido no resulta fundamentada la normalidad de los residuos. 

```{r}
#| echo: false 
# shapiro.test(residsDLM1)
```


```{r Diagnósticos}
#| echo: false 
#| fig-cap: 'Algunos diagnósticos descriptivos de los residuos para el modelo DLM polinomial de primer orden'
#| label: fig-diagDLM1


residsDLM1 <- residuals(filtroDLM1, sd = FALSE)
# checkresiduals( resids, test = F)

with_theme_cowplot <- function(expr) {
  orig <- theme_get()
  theme_set(theme_cowplot())
  force(expr)
  theme_set(orig)
}
g <- with_theme_cowplot(checkresiduals( residsDLM1, test = F, lag = 40))

```


```{r}
#| echo: false
# Se crea codigo para plotear los p values del estadistico Ljung-Box:


acfLDM1 <- acf(residsDLM1, plot = F)

acf_df <- data.frame(
  acf = acfLDM1$acf,
  lag = acfLDM1$lag
)


#Se calculan los p values del estadistico:
acf_df$pvalue <- sapply(acf_df$lag, function(i) Box.test(residsDLM1, lag=i, type="Ljung-Box")$p.value)

acf_df <-  acf_df[-1,] # Se elimina lag en 0.

```

```{r}
#| echo: false
#| fig-cap: ' Valores p del estadistico Ljung-Box para el modelo LDM polinomial de orden 1'
#| label: fig-pvaluesLjBDLM1

graficoLjungBoxDLM1 <- ggplot(data = acf_df) +
    geom_point(aes(lag,pvalue)) +
    geom_hline(yintercept = 0.05, color = "red", lty= 2) 
graficoLjungBoxDLM1 + theme_cowplot()

```


```{r}
#| echo: false 
#| fig-cap: 'Gráfico cuantil-cuantil de los residuos para el modelo DLM polinomial de primer orden'
#| label: fig-diagqqplotDLM1

 
# qqnorm(resids)
# qqline(resids)
# shapiro.test(resids)

ggqqplot(data= data.frame(residsDLM1),x="residsDLM1",
  color = "#2C7C7E",size = 1.6,
  shape = 1, conf.int.level = 0.95)+ 
  labs(x = "Cuantiles teóricos",
       y = "Cuantiles de muestra")+ 
  theme_minimal_hgrid()
```






### DLM polinomial de orden 2


```{r}
#| echo: false

#Se crea la estructura del modelo DLM orden 2:
DLMOrden2 <- function(parm) {
    dlmModPoly(order = 2, dV = exp(parm[1]), dW = exp(parm[2:3]))
           
}
#Se procede hacer ajuste de parametros via maxima verosimilitud:

ajusteDlmOrden2 <- dlmMLE(serie, rep(0, 3), build = DLMOrden2 , hessian = TRUE)


#Se crea el modelo con los parametros obtenidos via maxima verosimilitud:

modeloDlmOrden2 <- DLMOrden2(ajusteDlmOrden2$par)



```


```{r}
#| echo: false 

#Se aplica filtro de Kalman:

filtroDLM2 <-  dlmFilter(serie, mod = modeloDlmOrden2  )


#Procedemos hacer forecast, en este caso se hace se hace forecating 2 pasos adelante.


forecastDLM2 <-  dlmForecast(mod = filtroDLM2, nAhead = 2 )

```


```{r}
#| echo: false
#| fig-cap: 'Diagnóstico de residuos para el modelo DLM polinomial de segundo orden'
#| label: fig-diagDLM2


# Diagnostico de los residuos:

resids <-  residuals(filtroDLM2, sd = FALSE)
# Hacen varios plots para el chequeo de residuos.
checkresiduals( resids, test = F) + theme_minimal()


ggqqplot(data= data.frame(resids),x="resids",
  color = "#2C7C7E",size = 1,
  shape = 1, conf.int.level = 0.95)+ 
  labs(x = "Cuantiles teóricos",
       y = "Cuantiles de muestra")+ 
  theme_minimal_hgrid()
```
De los diagnósticos de los residuos  @fig-diagDLM2 se osberva del grafico de ACF que existe una baja correlación entre los residuos lo cual se confirma al aplicar la prueba  Ljung-Box. Se observa del gráfico superior de residuos la presencia de outliers, esto se ve reflejado el en el histograma de los residuos en la parte inferior derecha donde se ve que los residuos presentan colas de mayor peso que la distribución normal, no obstante al aplicar la prueba  Shapiro-Wilks de normalidad se observa que no se rechaza la hipotesis de normalidad.



```{r}
#| echo: false
#Se crea codigo para plotear los p values del estadistico Ljung-Box:


acf <- acf(resids , plot = F)
acf_df <- data.frame(
  acf = acf$acf,
  lag = acf$lag
)


#Se calculan los p values del estadistico:
acf_df$pvalue <- sapply(acf_df$lag, function(i) Box.test(resids, lag=i, type="Ljung-Box")$p.value)

acf_df <-  acf_df[-1,] # Se elimina lag en 0.

```

```{r}
#| echo: false
#| fig-cap: ' Valores p del estadistico Ljung-Box '
#| label: fig-pvaluesLjBDLM2

graficoLjungBoxDLM2 <- ggplot(data = acf_df) +
    geom_point(aes(lag,pvalue)) +
    geom_hline(yintercept = 0.05, color = "red", lty= 2) 
graficoLjungBoxDLM2

```

El grafico @fig-pvaluesLjBDLM2 muestra los p valores para el estadistico Ljung-Box donde se observa que los valores p se encuentran por encima del umbral con valor p de 0.05 (linea punteada), indicando que los residuos del modelo DLM polinomial de orden 2 son independientes. Concluimos, que el modelo ajusta bien o que el modelo no muestra una falta de ajuste.





```{r}
#| echo: false

#Se calcula el AIC, BIC y AICc 




loglikDLM2 <- dlmLL(serie, dlmModPoly(2))
numeroParametros <- 3
n <- length(serie)
AICDLM2 <- 2 * (numeroParametros) - 2*log(loglikDLM2)  
BICDLM2 <- (log(n)) * (numeroParametros)- 2*log(loglikDLM2)

AICcDLM2 <-  AICDLM2 + (2*(numeroParametros^(2) + numeroParametros))  /(n- numeroParametros-1)


#Se aplica el test Box-Ljung:

LjungTestDLM2 <-  Box.test(resids, lag = 12, type = "Ljung") 
# Valor p del test Box-Ljung:
valorPLjungTestDLM2 <-  LjungTestDLM2$p.value
# estadistico del test Box-Ljung Q:

estadPLjungTestDLM2 <- LjungTestDLM2$statistic


#Se aplica el test Shapiro:

ShapiTestDLM2 <-  shapiro.test(resids) 
# Valor p del test Shapiro:
valorPShapiTestDLM2 <-  ShapiTestDLM2$p.value

# estadistico del test Shapiro W:

estadShapiTestDLM2 <- ShapiTestDLM2$statistic




```


```{r}
#| echo: false
#| tbl-cap: "Resumen de diagnósticos de los modelos DLM polinomiales"
#| label: tbl-diagDLM
#| tbl-pos: 'h'


modeloDLM <- c(' DLM polinomial orden 2')

WDLM <-  c(estadShapiTestDLM2)

SwpDLM <- c(valorPShapiTestDLM2)

QDLM <- c(estadPLjungTestDLM2)

 LBpDLM <- c(valorPLjungTestDLM2)
 
 AICDLM <- c(AICDLM2)
 
 BICDLM <- c(BICDLM2)

 
 AICcDLM <- c(AICcDLM2)
 
data.frame(modeloDLM, WDLM, SwpDLM, QDLM, LBpDLM, AICDLM, BICDLM, AICcDLM) %>%
  kbl(
    digits = 2,
    col.names = c(
      'Modelo',
      'Estadístico W',
      "Valor p Shapiro-Wilks",
      "Estadístico Q",
      "Valor p Ljung-Box",
      "AIC",
      "BIC",
      "AICc"
    ), row.names=FALSE) %>%
  kable_styling(latex_options = c("striped"))  %>%
  kable_styling(full_width = F) %>% kable_classic_2() %>% row_spec(0, bold =
                                                                     TRUE)
```



Análogamente a los modelos ARIMA , la @tbl-diagDLM muestra las pruebas Shapiro-Wilks de normalidad y Ljung-Box de independencia de los residuos estandarizados. Para el caso de la prueba Shapiro-Wilks, no rechaza la hipótesis nula para el modelo DLM polinomial de orden 2, validando nuestra hipótesis de normalidad. Por otro lado, para la prueba Ljung-Box de independencia de los residuos estandarizados se da un no rechazo de la hipotesis nula, esto se observa al obtener un valor p de 0.16.

Los valores del AIC, AICc y BIC  se observan que son menores a los obtenidos por los modelos ARIMA mostrados en la tabla @tbl-forARIMA indicando que el modelo DLM polinomial de orden 2 mediante estos criterios es mejor modelo que los ARIMA.





```{r}
#| echo: false

#Se construyen intervalos de confianza para DLM polinomial orden 2:

#Varianza:

varDLM2 <-  unlist( forecastDLM2$Q)

#Desviacion estandar:

sdDLM2 <-  sqrt(varDLM2)

#Intervalo de confianza al 95%:

U95DLM2 <- forecastDLM2$f + sdDLM2*qnorm(1-0.95/2)
L95DLM2 <- forecastDLM2$f - sdDLM2*qnorm(1-0.95/2)

#Intervalo de confianza al 80%:

U80DLM2 <- forecastDLM2$f + sdDLM2*qnorm(1-0.80/2)
L80DLM2 <- forecastDLM2$f - sdDLM2*qnorm(1-0.80/2)

datosICDLM2 <- data.frame(c(2019, 2020),forecastDLM2$f  ,L80DLM2, U80DLM2, L95DLM2, U95DLM2)


```


```{r}
#| tbl-cap: "Intervalos de confianza del modelo DLM polinomial orden 2"
#| label: tbl-forDlm2
#| tbl-pos: 'h'
#| echo: false
datosICDLM2 %>% kbl(
  digits = 0,
  col.names = c('Año', 'pred', 'Lower80', 'Upper80', 'Lower95', 'Upper95')
) %>%
  kable_styling(latex_options = c("striped"))  %>%
  kable_styling(full_width = F) %>% kable_classic_2() %>% row_spec(0, bold =
                                                                     TRUE)
```


En @tbl-forDlm2 se muestran los pronósticos de defunciones realizados por el modelo para el año 2019 y 2020. Se muestran los intervalos de confianza al 80% y 95% de dichos pronósticos. Al comparar con los valores reales de 24292 para el 2019 y 26209 para el 2020 se observa que hay una diferencia de 442 y 644 defunciones aproximadamente.




```{r}
#| echo: false
abs( as.numeric(forecastDLM2$f) - base$defunciones[70:71])
```




