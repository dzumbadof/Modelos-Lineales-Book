

# Introducción

	
@REES2020239 afirma que una de las mayores contribuciones de la demografía ha sido el desarrollo de modelos para la proyección de futuras poblaciones, el cual es un tema de gran importancia para cualquier país, pues impacta directamente en sectores tan diversos como lo pueden ser la planificación urbana, el desarrollo humano sostenible, la demanda de bienes y servicios o los sistemas de pensiones. Además, esta permite estimar indicadores tan relevantes como la esperanza de vida. 

Se puede definir la proyección poblacional como el "cálculo de los cambios futuros en el número de personas, sujeto a ciertas hipótesis acerca de las tendencias futuras en las tasas de la fecundidad, mortalidad y migración" [@CCPconcepts].

Dentro de las proyecciones poblacionales se puede encontrar la proyección de la mortalidad, que está asociada directamente a las defunciones ocurridas en una población. En este trabajo se busca contestar la siguente pregunta de investigación: ¿Cómo se puede realizar un pronóstico de la serie de defunciones totales anuales de Costa Rica? Como puede notarse, la pregunta está totalmente circunsctira en el marco de la proyección poblacional. 

De forma más específica, en este trabajo se busca realizar un pronóstico de la cantidad de defunciones totales de Costa Rica para una ventana de tiempo de dos años (2019 y 2020) utilizando datos de 1950 al 2018. Para llevar a cabo este objetivo se consideran modelos ARIMA y modelos lineales generalizados, que son un caso particular de los modelos de espacio-estado. 




```{r, R.options, echo=F, include=F, warning=F, message=F}
options(knitr.kable.NA = '-', echo = F, scipen = 999)
library(readxl)
library(kableExtra)
library(dplyr)
library(janitor)
library(ggplot2)
library(wesanderson)
library(cowplot)
library(viridis)
library(GGally)
library(scales)
library(ggplot2)
library(ggpubr) # qqplots en ggplot2
#Paquetes para series de tiempo
library(astsa)
library(tseries)
library(forecast)


# Paquetes para DLM:
library(dlm)
library(ggmcmc) #Para ACF Y PACF DLM .

```


# Marco teórico

En términos generales, la demografía es "una ciencia que estudia las poblaciones humanas, su dimensión, estructura, evolución y características generales" [@bruno2019analisis] y además "estudia estadísticamente la estructura y la dinámica de las poblaciones, así como los procesos concretos que determinan su formación, conservación y desaparición [...] tales procesos son los de fecundidad, mortalidad y migración: emigración e inmigración"  [@bruno2019analisis].

De acuerdo al mismo autor, hay dos grandes tipos de demografía: la estática, que "estudia las poblaciones humanas en un momento de tiempo determinado desde un punto de vista de dimensión, territorio, estructura y características estructurales" [-@bruno2019analisis] y la dinámica, "que estudia las poblaciones humanas desde el punto de vista de la evolución en el transcurso del tiempo y los mecanismos por los que se modifica la dimensión, estructura y distribución geográfica de las poblaciones" [-@bruno2019analisis]. 

Bajo estas concepciones, el presente trabajo caería en el campo de la demografía dinámica, pues se buscará realizar pronóstico sobre la serie histórica de defunciones de Costa Rica de 1950 a 2020. En ese sentido, @REES2020239 afirma que una de las mayores contribuciones de la demografía ha sido el desarrollo de modelos para la proyección de futuras poblaciones, lo cuál está estrechamente relacionado con la proyección de defunciones.

Según @maccio1985diccionario la mortalidad o defunción se emplea para expresar la acción de la muerte sobre la población y esta se mide en valores absolutos y sobre el año calendario. Por su parte y de acuerdo a @brownlee, la realización de predicciones sobre el futuro se denomina extrapolación en el tratamiento estadístico clásico de los datos de las series temporales.

Los campos más modernos que se centran en el tema, lo denominan pronóstico de series temporales. El pronóstico consiste en tomar modelos ajustados a datos históricos y utilizarlos para predecir observaciones futuras. Asimismo, una serie cronológica o crónica se le llama a "la que forman los valores sucesivos que una cierta variable ha tomado en el transcurso del tiempo" [@maccio1985diccionario], como lo puede ser, por ejemplo, la serie de defunciones totales anuales para un país en específico.


Ahora bien, las teorías demográficas "pretenden explicar los patrones del crecimiento de la población en diversos países del mundo dando cuenta de la estructura y la dinámica de la población y estableciendo leyes o principios que regirían esos fenómenos" [@bruno2019analisis]. Más específicamente, una teoría demográfica "explicaría los cambios y acontecimientos de las poblaciones humanas, de su dimensión, estructura, evolución y características generales, tanto desde un punto de vista cuantitativo (estadístico) como cualitativo (biológico, sociológico, cultural y económico)" [@bruno2019analisis].

La primer teoría global de la población, es la malthusiana, enunciada por Thomas Robert Malthus en 1978 en su Ensayo sobre el principio de población, que consistió  "en una teoría donde se establece una ley general que explica el crecimiento total de la población en relación con otra variable fuera del contexto social, como lo es la disponibilidad de alimentos" [@sarrible2009teoria]. A su vez, explica que la teoría malthusiana propone que "el ritmo de crecimiento de la población responde a una progresión geométrica, mientras que el ritmo de aumento de los recursos para su supervivencia lo hace en progresión aritmética" [@bruno2019analisis].

De acuerdo a @mariscal2018tres, una de las teorías demográficas más importantes es la Teoría de la Transición Demográfica (TTD). Esta consiste en una generalización empírica en función de observaciones pasadas y establece una conexión entre la evolución demográfica de la población y el crecimiento económico [@mariscal2018tres].

El mismo autor explica que bajo el régimen demográfico, la TTD da pie a los modelos demográficos más importantes y esta "se produce cuando la natalidad y la mortalidad, o por lo menos uno de los dos fenómenos, ha dejado sus elevados niveles tradicionales para dirigirse hacia porcentajes más bajos, asociados a la fecundidad dirigida y al uso de métodos de lucha contra la natalidad, pasando de una demografía antigua y tradicional a otra moderna" [@alcalde2010teoria]. 

 
La Teoría de la transición epidemiológica (TTE) surge como alternativa teórica de la ya menciona Teoría de transición demográfica (TTD) debido a la naturaleza descriptiva o evolucionista de esta. La TTE tiene un carácter más multidisciplinar y con esto multifactorial.

Esta teoría establece que los principales factores causantes de las transiciones demográficas son los factores ecobiológicos de la mortalidad, factores biopsicológicos, como el uso de contraconceptivos ante el aumento de la supervivencia infantil generando un aumento de la EV, factores médicos y de salud pública, factores psicológicos o emocionales, y factores socioeconómicos, ya que los desarrollos económicos establecen los primeros sistemas sanitarios, ayudando así al descenso de la mortalidad y la reducción de la incidencia de las enfermedades infecciosas.

Es importante mencionar que tal como lo establece @mariscal2018tres la TTE, tiene como objeto de estudio la mortalidad, ya que se centra en aspectos como: patrones de enfermedad, causas de las muertes y la interacción de estas con patrones demográficos, económicos y sociológicos.


Como antecedentes, se observa que en múltiples investigaciones con temáticas relacionadas a defunciones como el de  @adekambi  y el estudio por @ordorika, se implementan modelos para el pronóstico de series defunciones mediante distintos enfoques, entre ellos pronóstico mediante el empleo de modelos ARIMA, sin embargo estudios más recientes hacen uso de los Modelos Dinámicos Lineales. 

Tal como lo establece  @petrisDLM entre los modelos más utilizados para el análisis de series temporales se encuentra la clase de modelos de media móvil autorregresiva (ARMA). Para enteros, no negativos $p$ y $q$, un modelo ARMA$(p,q)$ es definido mediante la notación:

$$Y_{t} = \mu + \sum_{j=1}^{p}\phi_{j}(Y_{t-j} - \mu ) +  \sum_{j=1}^{p}\psi_{j}\epsilon_{t-j} + \epsilon_{t}$$

Donde $(\epsilon_{t})$ es una ruido blanco Gaussiano con varianza $\sigma_{\epsilon}^{2}$ y los parámetros $\phi_{1}, \phi_{2}, ..., \phi_{p}$  satisfacen la condición de estacionariedad.

Cuando los datos no presentan estacionariedad, se suele tomar las diferencias hasta que se obtenga esta, una vez obtenida se procede a ajustar el modelo ARMA$(p,q)$ a los datos diferenciados.

Un modelo para un proceso cuya $d$-ésima diferencia sigue un modelo ARMA$(p,q)$ es llamado un ARIMA$(p ,d,q)$.  

Tal como lo establece @petrisDLM, los modelos dinámicos lineales  son una clase de Modelos de Espacio-Estado también llamados Modelos de Espacio-Estado Lineales Gaussianos, estos poseen dos supuestos, la linealidad y el supuesto de distribuciones Gaussianas. @petrisDLM señala que este último supuesto puede ser justificado mediante argumentos del teorema del límite central.


En general, el problema de pronóstico de $k$-pasos hacia adelante consiste en estimar la evolución del sistema $\theta_{t+k}$ para $k \geq 1$ y realizar un pronóstico de $k$-pasos para $Y_{t+k}$.

Según @petrisDLM en los DLM, el filtro de Kalman proporciona las fórmulas para actualizar nuestra inferencia actual sobre el vector de estado conforme se disponga de nuevos datos. 

Para un DLM, si se cumple que:

$$\theta_{t} | \mathcal{D}_{t} \sim \mathcal{N}(m_{t}, C_{t}) , t \geq 1$$


Se tiene que:

La densidad de predicción de estado de $k$-pasos con  $k \geq 1$ hacia adelante de $\theta_{t+k}$ dada  la información pasada $D_{t}$ es Gaussiana  con media y varianza condicional dadas respectivamente por:

$$a_{t}(k) = {E}[\theta_{t+k}|D_{t} ] = G_{t+k}a_{t, k-1}$$
$$R_{t}(k)= {Var}[\theta_{t+k}|D_{t} ] =G_{t+k}R_{t,k-1}G^{'}_{t+k} + W_{t+k}$$

La densidad de predicción de $k$-pasos con  $k \geq 1$ hacia adelante de $Y_{t+k}$ dada  la información pasada $D_{t}$, es Gaussiana  con media y varianza condicional dadas respectivamente por:

$$f_{t}(k) = {E}[Y_{t+k}|D_{t} ] =F_{t+k}a_{t}(k)$$

$$Q_{t}(k)= {Var}[Y_{t+k}|D_{t} ]  =F_{t+k}R_{t}(k)F^{'}_{t+k} + V_{t+k}$$

El DLM polinomial de orden 1 es descrito por el par de ecuaciones:
\[
\begin{aligned}
Y_t &=\mu_t+v_t, & v_t \sim \mathcal{N}(0, V) \\
\mu_t &=\mu_{t-1}+w_t, & w_t \sim \mathcal{N}(0, W)
\end{aligned}
\]

donde $(Y_{t})$ es, para efectos del presente análisis, el proceso del total de defunciones anuales de Costa Rica. 


Por otro lado, el modelo DLM polinomial de orden 2 se describe mediante las siguientes ecuaciones:

\[
\begin{aligned}
Y_t &=\theta_{t,1} + v_t, & v_t \sim \mathcal{N}(0, V) \\
\theta_{t,1} &=\theta_{t-1,1}+ \theta_{t-2,1} +w_{t,1}, & w_{t,1} \sim \mathcal{N}(0, W) \\
\theta_{t,2} &= \theta_{t-1,2} + w_{t,2}
\end{aligned}
\]




# Descripción de los datos

La tabla de datos proviene del Instituto Nacional de Estadística y Censos (INEC) de Costa Rica y es de acceso público, descargable desde la página web del instituto, como puede consultarse en @INEC_base. Esta base presenta los principales indicadores demográficos anuales de Costa Rica durante el periodo 1950-2020. Incluye en total 18 variables, entre las cuales están el año, la población total al 30 de junio de cada año, desagregado también por sexo, así como la cantidad de defunciones. Las variables presentes en la tabla son las siguientes: **Población de estudio:**La población de estudio son aquellas personas que vivían en Costa Rica entre los años 1950-2020 y mueren en este periodo. **Muestra observada:** La muestra observada, son todas aquellas personas que vivían en Costa Rica y al morir son  registrados por el Instituto Nacional de Estadística y Censo. **Unidad estadística o individuos**: La unidad estadística es el recuento anual de defunciones en Costa Rica. **Variables de estudio:** Son un total de 18 variables, las cuales según @INEC_conceptos se tiene: **Año:** Esta variable indica el año. **Total:** Esta variable registra la población total. **Hombres:** Esta variable registra la población total de hombres. **Mujeres:** Esta variable se encarga de registar el total de mujeres. **Nacimientos:** Esta variable registra el total de nacimientos. **Defunciones:** Esta variable registra el total de defunciones. **Defunciones infantiles:** Esta variable registra las defunciones de infantes (niños y niñas). **Defunciones neonatales:** Esta variable registra las defunciones de recién nacidos, hace referencia a la mortalidad de los nacidos antes de alcanzar los 28 días de edad. **Defunciones fetales:** Esta variable registra las defunciones de fetos, se refiere a la mortalidad de un bebé antes o durante el parto. **Tasa de crecimiento:** Esta variable registra la tasa de crecimiento de la población costarricense.Se refiere al crecimiento de la población entre dos fechas sin contemplar la migración.
**Tasa de natalidad:** Esta variable registra la tasa de nacimientos registrados en la población costarricenses. **Tasa de mortalidad:** Esta variable registra la tasa de muertes en su totalidad.
**Tasa de mortalidad infantil** Esta variable registra la tasa de muertes infantiles **Tasa de mortalidad neonatal:** Esta variable registra la tasa de muertes neonatales. **Tasa de mortalidad fetal:** En esta variable se registra la tasa de muertes fetales. **Tasa global de fecundidad:** Esta variable registra la tasa de fecundidad global (TGF), la cual indica cantidad de hijos e hijas que en promedio tendría cada mujer al final del periodo fértil, si durante su vida tiene sus hijos e hijas de acuerdo a las tasas de fecundidad por edad observadas en el país y año de interés y, además estas mujeres no están afectadas por la mortalidad desde el nacimiento hasta el final de periodo fértil.
**Tasa bruta de reproducción:** Esta variable hace referencia a el cantidad de hijas que en promedio
tendría cada mujer al final del periodo fértil, si durante su vida tiene sus hijos e hijas de acuerdo a las tasas de fecundidad por edad observadas en el país y año de interés y, además estas mujeres no están afectadas por la mortalidad desde el nacimiento hasta el final de periodo fértil. **Tasa neta de reproducción:** es el número de hijas que en promedio tendría cada mujer al final del periodo fértil, si durante su vida tiene sus hijos e hijas de acuerdo a las tasas de fecundidad por edad observadas en el país y año de interés y, además estas mujeres sí están afectadas por la mortalidad por edad observada en el país y año de interés desde el nacimiento hasta el final de periodo fértil.

# Análisis descriptivo de los datos

```{r}
#| echo: false
#| warning: false 
#| output: false
base <- data.frame(read_excel("sepoblacev1950-2020_0.xls", 
    range = "B9:S80", col_types = "numeric"))

colnames(base) <- c("Año",
                    "Población total",
                    "Población de hombres",
                    "Población de mujeres",
                    "Nacimientos",
                    "Defunciones",
                    "Defunciones infantiles",
                    "Defunciones neonatales",
                    "Defunciones fetales",
                    "Tasa de crecimiento",
                    "Tasa de natalidad",
                    "Tasa de mortalidad",
                    "Tasa de mortalidad infantil",
                    "Tasa de mortalidad neonatal",
                    "Tasa de mortalidad fetal",
                    "Tasa global de fecundidad",
                    "Tasa bruta de reproducción",
                    "Tasa neta de reproducción"				
)
```

En la tabla @tbl-resumen5numeros se detalla el resumen de cinco números para algunas variables relevantes de la tabla de datos. Se observa un rango bastante amplio (diferencia entre el máximo y mínimo) en las defunciones totales, lo que es de esperarse dado el crecimiento poblacional que se vio a partir de los 1980's y la cantidad de años que se registran en los datos. 

```{r, echo=F}
#| tbl-cap: "Resumen de cinco números para algunas variables de la tabla de datos"
#| label: tbl-resumen5numeros

resumen <- apply(base[,2:9], 2, fivenum) %>% as.data.frame()

row.names(resumen) <- c("Mínimo", "Primer cuartil", "Mediana", "Tercer cuartil", "Máximo") 

tabla <- resumen %>%
  kbl(align = rep('r', ncol(resumen)),
      format.args = list(big.mark = ' '),booktabs=T)  %>%  column_spec(1,bold = TRUE) %>%
  row_spec(0,bold=TRUE)  %>% 
      column_spec(1:9,width = "3cm") %>% 
  kable_styling(latex_options = c("striped", "condensed", "scale_down"))  %>%
  kable_styling(full_width = F) %>% 
  kable_classic_2() %>% 
  scroll_box()

tabla
```

En la tabla @tbl-estadisticos_dispersion se detallan los estadísticos de desviación estándar y rango intercuartílico para algunas variables relevante de la tabla de datos. Se observa que la variable población de hombres presenta mayor dispersión respecto población de mujeres, esta mayor variabilidad en la población de hombres se puede deber a diversos factores, entre ellos : una diferencia en el número de defunciones, nacimientos, o número de migrantes en la población masculina en relación con la de población femenina.

```{r, echo=F}
#| tbl-cap: "Estadísticos de dispersión para algunas variables de la tabla de datos"
#| label: tbl-estadisticos_dispersion 


estadisticos_dispersion <- function(x){
  return(c(sd(x), IQR(x)))
}

resumen <- apply(base[,2:9], 2, estadisticos_dispersion) %>% as.data.frame()

row.names(resumen) <- c("Desviación estándar", "Rango intercuartílico") 

tabla <- resumen %>%
  kbl(align = rep('r', ncol(resumen)),
      format.args = list(big.mark = ' '),booktabs=T)  %>%  column_spec(1,bold = TRUE) %>%
  row_spec(0,bold=TRUE)  %>% 
      column_spec(1:9,width = "3cm") %>% 
  kable_styling(latex_options = c("striped", "condensed", "scale_down"))  %>%
  kable_styling(full_width = F) %>% 
  kable_classic_2() %>% 
  scroll_box()

tabla
```

Una observación importante, es que los nacimientos presentan una mayor dispersión respecto a el número de defunciones. Es decir, se observa que el número defunciones anuales presenta menor desviación respecto a la media (desviación estándar) y una menor diferencia entre tercer cuartil y primer cuartil de defunciones (IQR).

Análogamente, se observa que para los tipos de defunción: infantil, neonatales y fetales. Se evidencia una mayor dispersión para las defunciones infantiles, seguidas de las neonatales y por último, con menor dispersión las defunciones fetales. 

Finalmente, se observa una diferencia significativa entre la medidas de dispersión desviación estándar y rango intercuartílico (IQR), esto se debe a la sensibilidad de la desviación estándar a valores extremos, es decir es  posible que existan valores extremos (muy alto o muy bajos respecto a la media) y por esta razón ambas medidas difieran considerablemente, sin embargo para este caso en particular el orden en el grado de dispersión (observe que la dispersión disminuye al avanzar en la tabla de izquierda a derecha) se mantiene para ambos medidas. 

```{r}
#| tbl-cap: "Frecuencia de defunciones, población y tasa de mortalidad"
#| label: tbl-freq1
#| tbl-pos: 'h'
#| echo: false
base <- base %>% clean_names()

df <- base %>% mutate( defunciones = cut(defunciones , breaks = 10)) %>% 
   group_by(defunciones) %>% 
   summarise(n_defunciones = n() )

df2 <- base %>% mutate( tamanio_poblacion = 
                          cut(poblacion_total, breaks = 10)) %>% 
   group_by( tamanio_poblacion ) %>% 
   summarise(n_pop = n() )

df3 <- base %>%
  mutate( tasas = cut(tasa_de_mortalidad, breaks = 11)) %>% 
   group_by( tasas ) %>% 
   summarise(n_pop = n() )

data.frame(df, df2, df3) %>%
  kbl( align = 'cccccc', col.names=c("Defunciones", 
                   "Frec. de defunciones", 
                   "Población total", 
                   "Frec. de poblacion", 
                   "Tasa de mortalidad", 
                   "Frec. de tasa"), 
       format.args = list(big.mark = ' '),booktabs=T) %>% 
  kable_styling(latex_options = c("striped", "condensed", "scale_down"))  %>%
  kable_styling(full_width = F) %>% 
  kable_classic_2() %>%
  row_spec(0,bold=TRUE) %>% 
  scroll_box()
```

De la @tbl-freq1 se observa que históricamente las defunciones totales de la mayoría de los años cae dentro del primero y segundo intervalo, con una distribución más uniforme dentro de los intervalos más altos. Por su parte la tasa de mortalidad bruta, la cual se aprecia en las columnas cinco y seis, se muestra que en la mayoría de años la tasa se ha mantenido entre 3.72 y 4.41. Esto quiere decir que la cantidad de defunciones relativo a la población ha sido más o menos constante en la mayoría de años. Por su parte, la población total se ha distribuido más uniformemente en todos los intervalos por lo que se concluye que el crecimiento población se ha movido más rápido que las defunciones.

```{r, echo=FALSE}
#| fig-cap: "Cantidad de defunciones por año para el periodo 1950-2020"
#| label: fig-defunciones_ano
#| fig-cap-location: top

g <- ggplot(base, aes(x=ano, y=defunciones))
g <- g + geom_point(size = 0.8)
g <- g + geom_smooth(formula = y~x, method = "loess", se = F)
g <- g + scale_x_continuous(breaks = seq(1950,2020,5))
g <- g + scale_y_continuous(breaks = seq(5000, 27000, 5000), limits = c(5000,27000))
g <- g + labs(x = "Año",
              y = "Cantidad de defunciones",
              caption = "Fuente: Elaboración propia")

g <- g + theme_cowplot() 

g <- g + theme(axis.text.x = element_text(angle = 45,vjust = 0.5, hjust=0.5))

g
```
En la @fig-defunciones_ano se muestra la cantidad total de defunciones para el periodo 1950-2020. Destaca una tendencia creciente muy marcada a partir de cerca de 1980 y hasta el final del periodo considerado. Esto muestra que se debe hacer una transformación a los datos para lograr la estacionareidad que supone el modelo ARMA. También se resalta que para el 2020 las defunciones totales se encuentran claramente por arriba de la tendencia lo cual se debe probablemente a la pandemia del Covid-19.

En la @fig-def_inf_neonat_fet_ano se comparan las defunciones infantiles, neonatales y fetales. Cabe añadir que la distancia vertical entre las defunciones infantiles y las neonatales resulta en las llamadas defunciones posneonatales, es decir, las que ocurren a partir de los 29 días de edad y hasta un año. Se advierte que a mediados de los años sesenta la cantidad de defunciones infantiles aparenta tener una tendencia decreciente. Al respecto, Rosero Bixby afirma que la caída más dramática en los años setenta "se logra gracias a los programas de atención primaria
de la salud, ayudados por una extraordinaria reducción de la natalidad que permite un mejor desarrollo intrauterino, mejor cuidado del niño y reduce el riesgo de contagio" [-@rosero2004situacion]. El mismo autor menciona que "el riesgo de morir de los menores de un
año ha disminuido en forma poco menos que espectacular entre 1970-78, pues ha sido
reducido a la tercera parte (de 62 a 22 muertes por cada mil nacimientos) en un lapso
de apenas 8 años" [@rosero2016situacion]. Por su parte, la cantidad de defunciones neonatales superó a las fetales desde mediados de los años cincuenta y hasta mediados de los años ochenta, donde se pierde un poco la noción de cuál suele ser mayor.

```{r, echo=FALSE}
#| fig-cap: "Defunciones infantiles, neonatales y fetales por año"
#| label: fig-def_inf_neonat_fet_ano
#| fig-cap-location: top
g <- ggplot(base)
g <- g + geom_line(aes(x=ano, y=defunciones_infantiles, color="Infantil"), lwd=1)
g <- g + geom_line(aes(x=ano, y=defunciones_neonatales, color="Neonatal"), lwd=1)
g <- g + geom_line(aes(x=ano, y=defunciones_fetales, color="Fetal"), lwd=1)
g <- g + scale_x_continuous(breaks = seq(1950,2020,5))
g <- g + labs(x = "Año",
              y = "Cantidad de defunciones",
              caption = "Fuente: Elaboración propia con datos del INEC",
              color="Tipo de defunción")
g <- g + theme_cowplot() 
g <- g + theme(axis.text.x = element_text(angle = 45,vjust = 0.5, hjust=0.5))
g <- g + scale_color_brewer(palette = "PuBuGn")
g
```

Para estudiar la asociación entre la tasa de defunciones neonatales y la de defunciones fetales, se crea una variable categórica indicadora de si la primera es mayor a la segunda. Dado que ambas tasas se calculan respecto al mismo denominador (la cantidad de nacimientos), esta variable equivale a hacer los mismo con la cantidad de defunciones respectiva. En la @fig-indicadora_neonat_fet se muestra la distribución de esta variable y se ve que en 15 de los 71 años considerados la tasa de mortalidad fetal fue mayor, donde de la @fig-def_inf_neonat_fet_ano se sabe que esto sucedió mayoritariamente entre 1985 y 2020. En consecuencia, en 56 años fue mayor la tasa de mortalidad neonatal, lo cuál sucede sobre todo en los primeros 35 años a partir de 1950. Entonces, en los 71 años de estudio, 78.87% de las ocasiones fue mayor la tasa de mortalidad neonatal, contra un 21.13% de la fetal.

```{r, echo=FALSE}
#| fig-cap: "Distribución variable indicadora de la mayor tasa entre las de mortalidad fetal y la neonatal"
#| label: fig-indicadora_neonat_fet
#| fig-cap-location: top

# Se crea variable que indica si la tasa de mortalidad neonatal es mayor a la fetal
datos <- base %>% mutate(indicadora = as.factor(tasa_de_mortalidad_neonatal>tasa_de_mortalidad_fetal))

g <- ggplot(datos) +
geom_bar(aes(indicadora, fill = indicadora), show.legend = FALSE)

g <- g + scale_x_discrete(labels = c("Fetal", "Neonatal"))
g <- g + scale_y_continuous(breaks = seq(0,60,5), limits = c(0,60))

g <- g + labs(x = "Tasa de mortalidad mayor",
              y = "Conteo",
              caption = "Fuente: Elaboración propia con datos del INEC",
              color="Tipo de tasa")
g <- g + theme_cowplot() 
g <- g + scale_fill_brewer(palette = "PuBuGn")
g

```



# Métodos y resultados

Primero, la @fig-serieDefunciones muestra la serie de tiempo de defunciones totales. Se muestra un comportamiento creciente de carácter lineal, por lo que se busca ajustar un modelo de la forma

$$D_t = \beta_0 + \beta_1t + x_T$$
Donde $D_t$ representa las defunciones totales, $t$ es el tiempo y $x_t$ es un proceso ARMA.

```{r}
#| echo: false
entrenamiento <- base$defunciones[30:69]
serie <- ts( entrenamiento, start=c(1980,1), frequency=1)
```

```{r}
#| fig-cap: "Serie de tiempo de defunciones totales"
#| label: fig-serieDefunciones
#| fig-cap-location: top
#| echo: false
plot(serie, main="", xlab="Tiempo", ylab='Defunciones totales')
```

```{r}
#| fig-cap: "ACF y PACF de los residuos de la regresión"
#| label: fig-acfRegresion
#| fig-cap-location: top
#| echo: false
fit1 <- lm(serie ~ time(serie))
t <- acf2(resid(fit1), main='')
```

De la @fig-acfRegresion se observa que logramos obtener residuos que lucen estacionarios. Además, parece que el PACF se trunca después del primer rezago, mientras que el ACF decrece. Esto sugiere fuertemente un modelo autoregresivo AR(1). Tambiés es posible que se trunque el ACF luego del primer o segundo rezago, mientras que el ACF decrece, por lo que también se tienen los modelos candidatos MA(1) Y MA(2)

```{r results='hide', fig.keep='all'}
#| echo: false
#| fig-cap: 'Diagnósticos del modelo con componentente ARMA(1,0)'
#| label: fig-diagAR1
#| message: false
modelo1 <- sarima(serie, 1,0,0, xreg=time(serie))
```

```{r results='hide',fig.keep='all'}
#| echo: false
#| fig-cap: 'Diagnósticos del modelo con componente ARMA(0,1)'
#| label: fig-diagARMA01
#| message: false
modelo2 <- sarima(serie, 0,0,1, xreg=time(serie))
```

```{r results='hide',fig.keep='all'}
#| echo: false
#| fig-cap: 'Diagnósticos del modelo ARMA(0,2)'
#| label: fig-diagARMA02
#| message: false
modelo3 <- sarima(serie, 0,0,2, xreg=time(serie))
```

```{r}
#| echo: false
Componente <- c('ARMA(1,0)', 'ARMA(0,1)' , 'ARMA(0,2)') 
W <- rep(NA, 3) #estadistico de Shapiro-Wilks
SWp <- rep(NA,3) #Valor p de prueba Shapiro-Wilks

Q <- rep(NA,3) #estadistico de Ljung-Box
LBp <- rep(NA,3) #valor p de prueba de Ljung-Box
```

```{r}
#| echo: false  
# Pruebas Shapiro-Wilks de normalidad y Ljung-Box de independencia

#Modelo ARIMA(0,1,1)
std.innov <- modelo1$fit$residuals/sqrt(modelo1$fit$sigma2)
W[1] <- shapiro.test(std.innov)$statistic
SWp[1] <- shapiro.test(std.innov)$p.value
Q[1] <- Box.test(std.innov, type='Ljung')$statistic
LBp[1] <- Box.test(std.innov, type='Ljung')$p.value

#Modelo ARIMA(1,1,0)
std.innov <- modelo2$fit$residuals/sqrt(modelo2$fit$sigma2)
W[2] <- shapiro.test(std.innov)$statistic
SWp[2] <- shapiro.test(std.innov)$p.value
Q[2] <- Box.test(std.innov, type='Ljung')$statistic
LBp[2] <- Box.test(std.innov, type='Ljung')$p.value

#Modelo ARIMA(1,1,1)
std.innov <- modelo3$fit$residuals/sqrt(modelo3$fit$sigma2)
W[3] <- shapiro.test(std.innov)$statistic
SWp[3] <- shapiro.test(std.innov)$p.value
Q[3] <- Box.test(std.innov, type='Ljung')$statistic
LBp[3] <- Box.test(std.innov, type='Ljung')$p.value
```

```{r}
#| echo: false
# AIC Y BIC de los modelos

AIC <- c(modelo1$AIC, modelo2$AIC, modelo3$AIC)
BIC <- c(modelo1$BIC, modelo2$BIC, modelo3$BIC)
AICc <- c(modelo1$AICc, modelo2$AICc, modelo3$AICc)
```


```{r}
#| tbl-cap: "Resumen de diagnósticos de los modelos propuestos"
#| label: tbl-diagARIMA
#| tbl-pos: 'h'
#| echo: false
data.frame(Componente, W, SWp, Q, LBp, AIC, BIC, AICc) %>%
  kbl(
    digits = 2,
    col.names = c(
      'Modelo',
      'Estadístico W',
      "Valor p Shapiro-Wilks",
      "Estadístico Q",
      "Valor p Ljung-Box",
      "AIC",
      "BIC",
      "AICc"
    )
  ) %>%
  kable_styling(latex_options = c("striped"))  %>%
  kable_styling(full_width = F) %>% kable_classic_2() %>% row_spec(0, bold =
                                                                     TRUE)
```

La @tbl-diagARIMA resume las pruebas Shapiro-Wilks de normalidad y Ljung-Box de independencia de los residuos estandarizados. Se da un no rechazo de las hipótesis nulas de independencia y normalidad de los residuos en el primer y tercer modelo. Además, se da un rechazo de la hipótesis de normalidad e independencia de los residuos en el segundo modelo. El modelo autoregresivo presenta las mejores medidas de AIC, AICc y BIC, aparte de ser el más parsimonioso de los tres. Por esta razón se decide escoger el modelo con componente ARMA(1,0) para hacer el pronóstico.

```{r}
#| fig-cap: 'Pronóstico del modelo con componente ARMA(1,0) de las defunciones totales'
#| label: fig-pronosticoARIMA
#| echo: false
def.for <- sarima.for(serie, n.ahead = 2, 1,0,0, xreg=time(serie), 
                      newxreg = c(2019,2020))
```

```{r}
#| echo: false
# Intervalos de confianza
U95 <- def.for$pred + def.for$se*qnorm(1-0.05/2)
L95 <- def.for$pred - def.for$se*qnorm(1-0.05/2)

U80 <- def.for$pred + def.for$se*qnorm(1-0.2/2)
L80 <- def.for$pred - def.for$se*qnorm(1-0.2/2)


for.int <- data.frame(c(2019, 2020), def.for$pred, L80, U80, L95, U95)
```

```{r}
#| tbl-cap: "Intervalos de predicción del modelo ARIMA(1,1,0)"
#| label: tbl-forARIMA
#| tbl-pos: 'h'
#| echo: false
for.int %>% kbl(
  digits = 0,
  col.names = c('Año', 'predicción', 'Inf80', 'Sup80', 'Inf95', 'Sup95')
) %>%
  kable_styling(latex_options = c("striped"))  %>%
  kable_styling(full_width = F) %>% kable_classic_2() %>% row_spec(0, bold =
                                                                     TRUE)
```

La @tbl-forARIMA muestra el valor pronosticado para las defunciones totales en los años 2019 y 2020 y los intervalos de confianza al 80% y 95%. Al comparar con los valores reales de 24292 para el 2019 y 26209 para el 2020, se observa que el valor real para el 2019 es consistente con el intervalo de confianza al 95%, pero no al 80%. Por su parte, el valor real para el 2020 se sale de los intervalos a ambos niveles de confianza. Esto es esperable pues el primer año de pandemia tuvo una cantidad inusualmente alta de muertes. La diferencia entre los valores predichos y los reales para el 2019 y 2020 son dados por

```{r}
#| echo: false
abs( as.numeric(def.for$pred) - base$defunciones[70:71])
```


Para utilizar un DLM polinomial de orden 1, se empieza por estimar los parámetros $V$ y $W$ correspondientes a la varianza de el ruido blanco gaussiano aditivo en las ecuaciones observada y del sistema, respectivamente. Esto se lleva a cabo por máxima verosimilitud, y se obtiene $\hat{V}=0.37$ y $\hat{W}=304117$. Nótese la gran diferencia en escala entre ambas varianzas. En @petrisDLM se advierte que este modelo en particular es muy sensible respecto al valor de la razón $\frac{W}{V}$, llamada *radio señal-ruido*. Cabe mencionar también que este proceso se comporta asintóticamente como un ARIMA(0,1,1) [@petrisDLM].


```{r Estimación DLM orden 1, echo=FALSE}
#| echo: false

serie1980 <- window(serie, start=1980)

# serie_insumo <- window( serie, end = 1979)
# m0_prueba = mean(serie_insumo)
# C0_prueba = var(serie_insumo)

# Se crea la estructura del modelo DLM orden 1:

DLMOrden1 <- function(parm) {
      dlmModPoly(order = 1, dV = exp(parm[1]), dW = exp(parm[2]))
}

# Se procede hacer ajuste de parametros vía maxima verosimilitud:

ajusteDlmOrden1 <- dlmMLE(serie1980, rep(0, 2), build = DLMOrden1, hessian = TRUE)


# Se crea el modelo con los parametros obtenidos vía maxima verosimilitud:

modeloDlmOrden1 <- DLMOrden1(ajusteDlmOrden1$par)

# round(modeloDlmOrden1$V, 2)
# round(modeloDlmOrden1$W, 2)
```


Una vez obtenidos estos parámetros, se procede a aplicar el filtro de Kalman y con este se realiza el pronóstico de la cantidad total de defunciones para 2019 y 2020, donde se encuentra un inconveniente: para ambos años, el pronóstico es de 23786 defunciones. Más aún, esta cantidad es justamente el total de defunciones en  2018. Sin duda esto representa una gran desventaja de este modelo pues claramente no resulta útil en términos de predicción, incluso teniendo en cuenta que solo es prudente tener pronósticos de corto plazo. Este  puede ser explicada por el gran desbalance que existe entre las varianzas de los ruidos de cada ecuación del modelo, lo que se traduce en un radio señal-ruido muy alto.

En efecto, en conformidad con @petrisDLM el filtro de Kalman para este simple modelo puede ser expresado de la siguiente manera:
\[
\begin{aligned}
y_{1: t-1} & \sim \mathcal{N}\left(m_{t-1}, R_t=C_{t-1}+W\right) \\
Y_t \mid y_{1: t-1} & \sim \mathcal{N}\left(f_t=m_{t-1}, Q_t=R_t+V\right) \\
\mu_t \mid y_{1: t} & \sim \mathcal{N}\left(m_t=m_{t-1}+K_t e_t, C_t=K_t V\right)
\end{aligned}
\]

donde la notación $y_{1: s}$ hace referencia a las observaciones $y_{1}, y_{2}, \dots, y_{s}$, $e_{t}=Y_{t}-f_{t}$ y

\[
K_{t}=\frac{R_{t}}{Q_{t}}=\frac{C_{t-1}+W}{C_{t-1}+W+V}=1-\frac{1}{\frac{C_{t-1}}{V}+\frac{W}{V}+1}.
\]
De la última ecuación se tiene que para valores altos de $\frac{W}{V}$, $K_{t}$ es cercano a 1. De las mismas ecuaciones que concede el filtro de Kalman se extrae la recursión
\[
m_{t}=K_{t}y_{t}+(1-K_{t})\,m_{t-1},
\]
de forma que $K_{t}$ funciona como un peso, y si $\frac{W}{V}$ es grande, entonces $m_{t}$ es "similar" a $y_{t}$ y, por lo tanto, el pronóstico a un paso se parece mucho a la última observación. En un caso extremo en que $V=0$, entonces $m_{t}=y_{t}$, es decir, el pronóstico a un paso es exactamente la observación más reciente. Es precisamente este fenómeno el que podría estar desembocando en el poco provecho del modelo en términos de sus pronósticos. 

```{r, echo=FALSE}
#| echo: false 

DLMOrden1 <- function(parm) {
      dlmModPoly(order = 1, 
                 dV = exp(parm[1]), 
                 dW = exp(parm[2]))
}
# Ajuste máxima verosimilitud
ajusteDlmOrden1 <- dlmMLE(serie1980, rep(0, 2), build = DLMOrden1, hessian = TRUE)
# Se aplica el filtro de Kalman:
filtroDLM1 <-  dlmFilter(serie1980, mod = modeloDlmOrden1)
# Se realiza el pronóstico
forecastDLM1 <-  dlmForecast(mod = filtroDLM1, nAhead = 2)
# forecastDLM1$f
```

```{r Pronóstico DLM orden 1}
#| echo: false 

# Se aplica el filtro de Kalman:

filtroDLM1 <-  dlmFilter(serie1980, mod = modeloDlmOrden1)

# Procedemos a hacer forecast, en este caso se hace se hace forecating 2 pasos adelante.

forecastDLM1 <-  dlmForecast(mod = filtroDLM1, nAhead = 2)

# forecastDLM1


```

En cuanto a los diagnósticos del modelo, en la @fig-diagDLM1 se observa del gráfico de residuos que hay algunos de estos muy cercanos a 2 en valor absoluto, aunque en general no se aprecia con claridad un valor extremo. Por su parte, en el ACF, la proporción de excepciones a la regla empírica es adecuada, siendo una proporción menor al 5% del total de rezagos usados (20), de modo que estos parecen no estar correlacionados. Con la prueba de Ljung-Box en la @fig-pvaluesLjBDLM1 se ve aún más sustentado que los residuos no estén correlacionados. Sin embargo, hay graves problemas con el supuesto de normalidad. En primera instancia, del histograma presente en la @fig-diagDLM1, el ajuste normal parece no ser bueno. Esto se constata con el gráfico cuantil-cuantil en la @fig-diagqqplotDLM1, donde se nota un muy mal ajuste en ambas colas. A pesar de que con pruebas como la de Shapiro-Wilk no se rechazaría la hipótesis de normalidad con niveles de significancia usuales del 1% y 5%, teniéndose un valor p de cerca del 8%, del gráfico cuantil-cuantil ya discutido no resulta fundamentada la normalidad de los residuos. 

```{r}
#| echo: false 
# shapiro.test(residsDLM1)
```


```{r Diagnósticos}
#| echo: false 
#| fig-cap: 'Algunos diagnósticos descriptivos de los residuos para el modelo DLM polinomial de primer orden'
#| label: fig-diagDLM1


residsDLM1 <- residuals(filtroDLM1, sd = FALSE)
# checkresiduals( resids, test = F)

with_theme_cowplot <- function(expr) {
  orig <- theme_get()
  theme_set(theme_cowplot())
  force(expr)
  theme_set(orig)
}
g <- with_theme_cowplot(checkresiduals( residsDLM1, test = F, lag = 40))

```


```{r}
#| echo: false
# Se crea codigo para plotear los p values del estadistico Ljung-Box:


acfLDM1 <- acf(residsDLM1, plot = F)

acf_df <- data.frame(
  acf = acfLDM1$acf,
  lag = acfLDM1$lag
)


#Se calculan los p values del estadistico:
acf_df$pvalue <- sapply(acf_df$lag, function(i) Box.test(residsDLM1, lag=i, type="Ljung-Box")$p.value)

acf_df <-  acf_df[-1,] # Se elimina lag en 0.

```

```{r}
#| echo: false
#| fig-cap: ' Valores p del estadistico Ljung-Box para el modelo LDM polinomial de orden 1'
#| label: fig-pvaluesLjBDLM1
#| message: false

graficoLjungBoxDLM1 <- ggplot(data = acf_df) +
    geom_point(aes(lag,pvalue)) +
    geom_hline(yintercept = 0.05, color = "red", lty= 2) 
graficoLjungBoxDLM1 + theme_cowplot()

```


```{r}
#| echo: false 
#| fig-cap: 'Gráfico cuantil-cuantil de los residuos para el modelo DLM polinomial de primer orden'
#| label: fig-diagqqplotDLM1
#| message: false

 
# qqnorm(resids)
# qqline(resids)
# shapiro.test(resids)

ggqqplot(data= data.frame(residsDLM1),x="residsDLM1",
  color = "#2C7C7E",size = 1.6,
  shape = 1, conf.int.level = 0.95)+ 
  labs(x = "Cuantiles teóricos",
       y = "Cuantiles de muestra")+ 
  theme_minimal_hgrid()
```




```{r}
#| echo: false

#Se crea la estructura del modelo DLM orden 2:
DLMOrden2 <- function(parm) {
    dlmModPoly(order = 2, dV = exp(parm[1]), dW = exp(parm[2:3]))
           
}
#Se procede hacer ajuste de parametros via maxima verosimilitud:

ajusteDlmOrden2 <- dlmMLE(serie, rep(0, 3), build = DLMOrden2 , hessian = TRUE)


#Se crea el modelo con los parametros obtenidos via maxima verosimilitud:

modeloDlmOrden2 <- DLMOrden2(ajusteDlmOrden2$par)



```


```{r}
#| echo: false 

#Se aplica filtro de Kalman:

filtroDLM2 <-  dlmFilter(serie, mod = modeloDlmOrden2  )


#Procedemos hacer forecast, en este caso se hace se hace forecating 2 pasos adelante.


forecastDLM2 <-  dlmForecast(mod = filtroDLM2, nAhead = 2 )

```


```{r results='hide',fig.keep='all'}
#| echo: false
#| fig-cap: 'Diagnóstico de residuos para el modelo DLM polinomial de segundo orden'
#| label: fig-diagDLM2
#| message: false


# Diagnostico de los residuos:

resids <-  residuals(filtroDLM2, sd = FALSE)
# Hacen varios plots para el chequeo de residuos.
checkresiduals( resids, test = F) + theme_minimal()

```

De los diagnósticos de los residuos @fig-diagDLM2 se osberva del grafico de ACF que existe una baja correlación entre los residuos lo cual se confirma al aplicar la prueba  Ljung-Box. Se observa del gráfico superior de residuos la presencia de outliers, esto se ve reflejado el en el histograma de los residuos en la parte inferior derecha donde se ve que los residuos presentan colas de mayor peso que la distribución normal, no obstante al aplicar la prueba  Shapiro-Wilks de normalidad se observa que no se rechaza la hipotesis de normalidad.

```{r}
#| echo: false 
#| fig-cap: 'Gráfico cuantil-cuantil de los residuos para el modelo DLM polinomial de segundo orden'
#| label: fig-diagqqplotDLM2
#| message: false
ggqqplot(data= data.frame(resids),x="resids",
  color = "#2C7C7E",size = 1,
  shape = 1, conf.int.level = 0.95)+ 
  labs(x = "Cuantiles teóricos",
       y = "Cuantiles de muestra")+ 
  theme_minimal_hgrid()
```

De la @fig-diagqqplotDLM2 se ve que el ajuste normal es bueno salvo hacia la cola izquierda.

```{r}
#| echo: false
#Se crea codigo para plotear los p values del estadistico Ljung-Box:


acf <- acf(resids , plot = F)
acf_df <- data.frame(
  acf = acf$acf,
  lag = acf$lag
)


#Se calculan los p values del estadistico:
acf_df$pvalue <- sapply(acf_df$lag, function(i) Box.test(resids, lag=i, type="Ljung-Box")$p.value)

acf_df <-  acf_df[-1,] # Se elimina lag en 0.

```

```{r}
#| echo: false
#| fig-cap: ' Valores p del estadistico Ljung-Box '
#| label: fig-pvaluesLjBDLM2
#| message: false

graficoLjungBoxDLM2 <- ggplot(data = acf_df) +
    geom_point(aes(lag,pvalue)) +
    geom_hline(yintercept = 0.05, color = "red", lty= 2) 
graficoLjungBoxDLM2

```

El grafico @fig-pvaluesLjBDLM2 muestra los p valores para el estadistico Ljung-Box donde se observa que los valores p se encuentran por encima del umbral con valor p de 0.05 (linea punteada), indicando que los residuos del modelo DLM polinomial de orden 2 son independientes. Concluimos, que el modelo ajusta bien o que el modelo no muestra una falta de ajuste.





```{r}
#| echo: false

#Se calcula el AIC, BIC y AICc 




loglikDLM2 <- dlmLL(serie, dlmModPoly(2))
numeroParametros <- 3
n <- length(serie)
AICDLM2 <- 2 * (numeroParametros) - 2*log(loglikDLM2)  
BICDLM2 <- (log(n)) * (numeroParametros)- 2*log(loglikDLM2)

AICcDLM2 <-  AICDLM2 + (2*(numeroParametros^(2) + numeroParametros))  /(n- numeroParametros-1)


#Se aplica el test Box-Ljung:

LjungTestDLM2 <-  Box.test(resids, lag = 12, type = "Ljung") 
# Valor p del test Box-Ljung:
valorPLjungTestDLM2 <-  LjungTestDLM2$p.value
# estadistico del test Box-Ljung Q:

estadPLjungTestDLM2 <- LjungTestDLM2$statistic


#Se aplica el test Shapiro:

ShapiTestDLM2 <-  shapiro.test(resids) 
# Valor p del test Shapiro:
valorPShapiTestDLM2 <-  ShapiTestDLM2$p.value

# estadistico del test Shapiro W:

estadShapiTestDLM2 <- ShapiTestDLM2$statistic




```


```{r}
#| echo: false
#| tbl-cap: "Resumen de diagnósticos de los modelos DLM polinomiales"
#| label: tbl-diagDLM
#| tbl-pos: 'h'


modeloDLM <- c(' DLM polinomial orden 2')

WDLM <-  c(estadShapiTestDLM2)

SwpDLM <- c(valorPShapiTestDLM2)

QDLM <- c(estadPLjungTestDLM2)

 LBpDLM <- c(valorPLjungTestDLM2)
 
 AICDLM <- c(AICDLM2)
 
 BICDLM <- c(BICDLM2)

 
 AICcDLM <- c(AICcDLM2)
 
data.frame(modeloDLM, WDLM, SwpDLM, QDLM, LBpDLM, AICDLM, BICDLM, AICcDLM) %>%
  kbl(
    digits = 2,
    col.names = c(
      'Modelo',
      'Estadístico W',
      "Valor p Shapiro-Wilks",
      "Estadístico Q",
      "Valor p Ljung-Box",
      "AIC",
      "BIC",
      "AICc"
    ), row.names=FALSE) %>%
  kable_styling(latex_options = c("striped"))  %>%
  kable_styling(full_width = F) %>% kable_classic_2() %>% row_spec(0, bold =
                                                                     TRUE)
```



Análogamente a los modelos ARIMA , la @tbl-diagDLM muestra las pruebas Shapiro-Wilks de normalidad y Ljung-Box de independencia de los residuos estandarizados. Para el caso de la prueba Shapiro-Wilks, no rechaza la hipótesis nula para el modelo DLM polinomial de orden 2, validando nuestra hipótesis de normalidad. Por otro lado, para la prueba Ljung-Box de independencia de los residuos estandarizados se da un no rechazo de la hipotesis nula, esto se observa al obtener un valor p de 0.16.

Los valores del AIC, AICc y BIC  se observan que son menores a los obtenidos por los modelos ARIMA mostrados en la tabla @tbl-forARIMA indicando que el modelo DLM polinomial de orden 2 mediante estos criterios es mejor modelo que los ARIMA.





```{r}
#| echo: false

#Se construyen intervalos de confianza para DLM polinomial orden 2:

#Varianza:

varDLM2 <-  unlist( forecastDLM2$Q)

#Desviacion estandar:

sdDLM2 <-  sqrt(varDLM2)

#Intervalo de confianza al 95%:

U95DLM2 <- forecastDLM2$f + sdDLM2*qnorm(1-0.05/2)
L95DLM2 <- forecastDLM2$f - sdDLM2*qnorm(1-0.05/2)

#Intervalo de confianza al 80%:

U80DLM2 <- forecastDLM2$f + sdDLM2*qnorm(1-0.2/2)
L80DLM2 <- forecastDLM2$f - sdDLM2*qnorm(1-0.2/2)

datosICDLM2 <- data.frame(c(2019, 2020),forecastDLM2$f  ,L80DLM2, U80DLM2, L95DLM2, U95DLM2)


```


```{r}
#| tbl-cap: "Intervalos de predicción del modelo DLM polinomial orden 2"
#| label: tbl-forDlm2
#| tbl-pos: 'h'
#| echo: false
datosICDLM2 %>% kbl(
  digits = 0,
  col.names = c('Año', 'predicción', 'Inf80', 'Sup80', 'Inf95', 'Sup95')
) %>%
  kable_styling(latex_options = c("striped"))  %>%
  kable_styling(full_width = F) %>% kable_classic_2() %>% row_spec(0, bold =
                                                                     TRUE)
```


En @tbl-forDlm2 se muestran los pronósticos de defunciones realizados por el modelo para el año 2019 y 2020. Se muestran los intervalos de confianza al 80% y 95% de dichos pronósticos. Al comparar con los valores reales de 24292 para el 2019 y 26209 para el 2020 se observa que hay una diferencia de 410 y 719 defunciones aproximadamente.



# Conclusiones

Ambos modelos estudiados logran hacer pronósticos a dos años de las defunciones que son consistentes con las reales. En el caso del ARIMA, el dato real para el 2020 se sale del intervalo de confianza al 80% y al 95%, mientras que el DLM polinomial de orden dos logran crear intervalo más certeros. Además, el segundo modelo parece ser menos conservador con las predicciones para la serie utilizada. 

Si bien el modelo DLM polinomial de orden no logra ser tan preciso como el ARIMA para el año 2019, sí logra ser más preciso para el año 2020, mostrando un mejor ajuste para lo que se consideraría un año extraordinario por ser el primer año de pandemia.  

Los pronósticos hechos por el modelo DLM polinimal de orden 1 no resultan útiles producto de la razón señal-ruido tan alta, Sin embargo, este resultado es consistente con el modelo. 


# Limitaciones 

La limitación más clara del modelo ARIMA, es que al hacer pronósticos a largo plazo rápidamente se va a la media del proceso por lo que se imposibilita hacer pronósticos con una ventana de tiempo más amplia de la presentada en este proyecto.

Tal como lo establece @optimalDLM el modelo DLM polinomial de orden 2  ha demostrado ser suficiente para  pronósticos a corto plazo, no obstante una de sus grandes limitaciones al igual que los modelos ARIMA es que los pronósticos a largo plazo son deficientes. Dicho esto concluimos por tanto, en general nuestro estudio está limitado a  pronósticos de defunciones totales a corto plazo.

# Recomendaciones

La mayoría de trabajos sobre demografía estadística para el caso costarricense que se consultaron fueron de corte descriptivo, con la excepción notable del de @aguilar2013estimacion, quien justamente realiza una proyección sobre la mortalidad. En este trabajo se emplea el método Lee-Carter, que es un modelo de muy recurrente mención en la literatura sobre proyecciones demográficas, siendo también empleado por el mismo Instituto Nacional de Estadísticas y Censos [@INEC_proyecciones] para la proyección de la mortalidad, por lo cuál debería considerarse la posibilidad de emplearlo y/o compararlo con otros métodos. Además, una de las características de estos trabajos es que no consideran la mortalidad de forma aislada, como se hace en el presente análisis, sino que las proyecciones involucran a los tres componentes del cambio poblacional (fecundidad, mortalidad y migración). También, debe mencionarse que estas proyecciones trabajan sobre datos mucho más específicos y pormenorizados, teniendo en cuenta conteos desagregados por edad (o grupo de edad) y sexo. En ese sentido, se cree para futuras extensiones de esta investigación y obedeciendo a la literatura afín, sin duda alguna se recomienda tratar de localizar datos que, primero, al menos estén desagregados por sexo y, segundo, que estos además tengan en cuenta distintos grupos de edad. También, podía valorarse la inclusión de covariables, como lo pueden ser tasas de criminalidad, indicadores de salud o también una variable de la población total rezagada.







# UVE de Gowin

![UVE Heurística](Images/UVE2.png){fig-align="center" width="600"}
